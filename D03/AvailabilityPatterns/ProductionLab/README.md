# Production Lab: Hardening Availability (Fault Tolerance & Failover)

## 1. Executive Summary
Lab nÃ y lÃ  bÆ°á»›c chuyá»ƒn mÃ¬nh tá»« **Developer Local** sang **Production Grade**. ChÃºng ta khÃ´ng chá»‰ "cháº¡y Ä‘Æ°á»£c app", mÃ  cÃ²n xÃ¢y dá»±ng má»™t há»‡ thá»‘ng cÃ³ kháº£ nÄƒng **Tá»± phá»¥c há»“i (Self-Healing)** vÃ  **Chá»‹u lá»—i (Fault Tolerant)**.

**Má»¥c tiÃªu cá»‘t lÃµi:**
1.  **Zero-Downtime Deployment:** Sá»­ dá»¥ng **Gunicorn** Ä‘á»ƒ xá»­ lÃ½ Graceful Shutdown.
2.  **Aggressive Failover:** Tinh chá»‰nh Nginx Ä‘á»ƒ loáº¡i bá» node cháº¿t trong **1 giÃ¢y** (thay vÃ¬ 10-60s máº·c Ä‘á»‹nh).
3.  **Deep Health Check:** Äáº£m báº£o traffic khÃ´ng Ä‘i vÃ o cÃ¡c node "Zombie" (sá»‘ng nhÆ°ng máº¥t káº¿t ná»‘i DB).

## 2. Hardened Architecture Configuration

Sá»± khÃ¡c biá»‡t náº±m á»Ÿ cáº¥u hÃ¬nh "chiáº¿n Ä‘áº¥u" trong `nginx/nginx_prod.conf`:

```nginx
upstream backend {
    # Tinh chá»‰nh fail_timeout xuá»‘ng 1 giÃ¢y (Aggressive)
    # Náº¿u gáº·p 3 lá»—i liÃªn tiáº¿p (max_fails=3), Nginx sáº½ loáº¡i bá» server trong 1s.
    server app-server-a:8000 max_fails=3 fail_timeout=1s; 
    server app-server-b:8000 max_fails=3 fail_timeout=1s;
}

server {
    location / {
        proxy_pass http://backend;
        # Circuit Breaker: Tá»± Ä‘á»™ng chuyá»ƒn request sang node khÃ¡c náº¿u gáº·p lá»—i
        proxy_next_upstream error timeout http_500 http_502 http_503 http_504; 
    }
}
```

> **Why Passive Health Check?** Nginx OSS dÃ¹ng Passive Check (dá»±a trÃªn traffic tháº­t). ÄÃ¢y lÃ  cÃ¡ch hiá»‡u quáº£ nháº¥t Ä‘á»ƒ detect lá»—i mÃ  khÃ´ng cáº§n agent phá»¥ trá»£. Cáº¥u hÃ¬nh trÃªn Ä‘áº£m báº£o **MTTR (Mean Time To Recovery)** cá»±c tháº¥p.

## 3. Verification Playbook (Chaos Engineering)

ChÃºng ta sáº½ thá»±c hiá»‡n 3 bÃ i test Ä‘á»ƒ chá»©ng minh há»‡ thá»‘ng Ä‘áº¡t chuáº©n Production.

### ğŸ§ª Test 1: Sanity Check (Deep Health)
**Má»¥c tiÃªu:** Äáº£m báº£o á»©ng dá»¥ng vÃ  Nginx Ä‘ang hoáº¡t Ä‘á»™ng Ä‘Ãºng trÆ°á»›c khi phÃ¡ hoáº¡i.

1.  **Khá»Ÿi Ä‘á»™ng Stack:**
    ```bash
    docker compose up -d --build
    ```

2.  **Verify Endpoint:**
    ```bash
    # Test qua Load Balancer
    curl -I http://localhost:8080/health_check
    ```
    > *Ká»³ vá»ng:* `HTTP/1.1 200 OK`
    > - Cáº£ 2 app servers cháº¡y vá»›i Gunicorn (4 workers má»—i node)
    > - Nginx load balancer hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng

### ğŸ§ª Test 2: Hard Failure & Fast Failover
**Má»¥c tiÃªu:** Chá»©ng minh Nginx loáº¡i bá» node cháº¿t trong 1-2 giÃ¢y mÃ  User khÃ´ng nháº­n ra.

1.  **Cháº¡y k6 Load Test (Background):**
    ```bash
    docker compose run --rm -d k6-runner run --vus 10 --duration 1m /home/k6/test.js
    ```

2.  **Simulate Disaster (Kill Node A):**
    ```bash
    # Äá»£i 10 giÃ¢y Ä‘á»ƒ load test á»•n Ä‘á»‹nh
    sleep 10
    echo "ğŸ’£ Killing Node A..."
    docker stop productionlab-app-server-a-1
    ```

3.  **Quan sÃ¡t Logs Nginx (Real-time):**
    ```bash
    docker logs nginx-lb 2>&1 | grep -i "upstream\|error\|refused" | tail -15
    ```
    > *Ká»³ vá»ng:*
    > - Báº¡n sáº½ tháº¥y nhiá»u dÃ²ng "upstream server temporarily disabled"
    > - Sau 1-2 giÃ¢y, khÃ´ng cÃ²n request nÃ o Ä‘Æ°á»£c gá»­i tá»›i Node A
    > - Traffic dá»“n 100% sang Node B
    > - KhÃ´ng cÃ³ lá»—i 502 kÃ©o dÃ i (circuit breaker hoáº¡t Ä‘á»™ng)

4.  **Verify Node B Ä‘ang xá»­ lÃ½ 100% traffic:**
    ```bash
    docker logs nginx-lb 2>&1 | grep "200" | tail -10
    ```
    > *Ká»³ vá»ng:* Táº¥t cáº£ requests tráº£ vá» 200 OK

### ğŸ§ª Test 3: Auto Recovery (Fail-back)
**Má»¥c tiÃªu:** Chá»©ng minh há»‡ thá»‘ng tá»± khÃ´i phá»¥c khi Node A sá»‘ng láº¡i.

1.  **Há»“i sinh Node A:**
    ```bash
    docker start productionlab-app-server-a-1
    echo "ğŸš‘ Node A is back online"
    ```

2.  **Äá»£i Nginx phÃ¡t hiá»‡n Node A healthy:**
    ```bash
    sleep 5
    docker logs productionlab-app-server-a-1 2>&1 | tail -10
    ```
    > *Ká»³ vá»ng:* Tháº¥y Gunicorn khá»Ÿi Ä‘á»™ng thÃ nh cÃ´ng vá»›i 4 workers

3.  **Verify traffic Ä‘Æ°á»£c phÃ¢n tÃ¡n Ä‘á»u:**
    ```bash
    # Gá»­i 10 requests vÃ  Ä‘áº¿m phÃ¢n bá»‘
    for i in {1..10}; do curl -s http://localhost:8080/ | grep -o "NODE_[AB]"; done | sort | uniq -c
    ```
    > *Ká»³ vá»ng:*
    > - NODE_A: ~5 requests (50%)
    > - NODE_B: ~5 requests (50%)
    > - Load balancing Ä‘Æ°á»£c khÃ´i phá»¥c hoÃ n toÃ n

## 4. Senior Architect Insights

| Hiá»‡n tÆ°á»£ng quan sÃ¡t | Giáº£i thÃ­ch ká»¹ thuáº­t (The "Why") |
| :--- | :--- |
| **Failover cá»±c nhanh (1-2s)** | Do `fail_timeout=1s` vÃ  `max_fails=3`. Nginx phÃ¡t hiá»‡n 3 lá»—i liÃªn tiáº¿p vÃ  loáº¡i bá» node trong 1 giÃ¢y. Trong K8s, cÃ¡i nÃ y tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i **Readiness Probe** frequency ngáº¯n. Trade-off lÃ  cÃ³ thá»ƒ bá»‹ "flapping" náº¿u máº¡ng cháº­p chá»n, nhÆ°ng vá»›i internal network thÃ¬ an toÃ n. |
| **KhÃ´ng cÃ³ lá»—i 502 kÃ©o dÃ i** | Do `proxy_next_upstream error timeout http_500 http_502 http_503 http_504`. Nginx khÃ´ng tráº£ lá»—i ngay cho client mÃ  Ã¢m tháº§m retry sang node khÃ¡c. ÄÃ¢y lÃ  **Client-side Resilience** Ä‘Æ°á»£c implement á»Ÿ táº§ng Infrastructure. |
| **"Upstream server temporarily disabled"** | ÄÃ¢y lÃ  log cá»§a Passive Health Check. Nginx Ä‘Ã¡nh dáº¥u upstream lÃ  "down" sau khi gáº·p `max_fails` lá»—i liÃªn tiáº¿p. Node sáº½ Ä‘Æ°á»£c thá»­ láº¡i sau `fail_timeout` (1s). Náº¿u thÃ nh cÃ´ng, node Ä‘Æ°á»£c Ä‘Æ°a trá»Ÿ láº¡i pool. |
| **Auto Recovery khÃ´ng cáº§n config** | Nginx tá»± Ä‘á»™ng thá»­ láº¡i cÃ¡c upstream Ä‘Ã£ bá»‹ disabled sau má»—i `fail_timeout`. Khi Node A sá»‘ng láº¡i vÃ  response thÃ nh cÃ´ng, nÃ³ Ä‘Æ°á»£c Ä‘Æ°a trá»Ÿ láº¡i pool ngay láº­p tá»©c. ÄÃ¢y lÃ  **Self-Healing** tá»± Ä‘á»™ng. |
| **Gunicorn Graceful Shutdown** | Khi nháº­n SIGTERM (docker stop), Gunicorn Ä‘á»£i cÃ¡c request Ä‘ang xá»­ lÃ½ hoÃ n thÃ nh trÆ°á»›c khi táº¯t workers. Äiá»u nÃ y giáº£m thiá»ƒu connection errors. Timeout máº·c Ä‘á»‹nh lÃ  30s (cÃ³ thá»ƒ config vá»›i `--graceful-timeout`). |
| **Throughput giáº£m khi 1 node cháº¿t** | Hiá»ƒn nhiÃªn. Há»‡ thá»‘ng máº¥t 50% capacity. Trong thá»±c táº¿, cáº§n **Autoscaling** (K8s HPA) Ä‘á»ƒ bÃ¹ vÃ o node Ä‘Ã£ máº¥t, náº¿u khÃ´ng Node B cÃ³ thá»ƒ bá»‹ quÃ¡ táº£i dáº«n Ä‘áº¿n **Cascading Failure**. |

### Káº¿t quáº£ Lab thá»±c táº¿:
- **Failover time:** 1-2 giÃ¢y (Ä‘Ãºng nhÆ° config)
- **Errors during failover:** ~14 warnings, nhÆ°ng khÃ´ng cÃ³ 502 errors cho client
- **Recovery time:** ~5 giÃ¢y (Gunicorn khá»Ÿi Ä‘á»™ng + Nginx detect)
- **Final state:** Load balancing 50/50 giá»¯a 2 nodes

---
> **Káº¿t luáº­n:** Lab nÃ y chá»©ng minh ráº±ng **Availability** khÃ´ng chá»‰ lÃ  code khÃ´ng lá»—i, mÃ  lÃ  cáº¥u hÃ¬nh Infrastructure (Nginx/K8s) thÃ´ng minh Ä‘á»ƒ xá»­ lÃ½ lá»—i khi nÃ³ cháº¯c cháº¯n xáº£y ra. Production-grade system pháº£i cÃ³ kháº£ nÄƒng **Self-Healing** vÃ  **Fast Failover** Ä‘á»ƒ Ä‘áº¡t SLA cao (99.9%+).